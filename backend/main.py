import uvicorn
from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from sqlalchemy.orm import Session
import os
import dotenv
import google.generativeai as genai

# Import models, database session, and crud functions
from models import ChatRequest, ChatResponse
from database import create_db_and_tables, SessionLocal
import crud

# Import emotion system
from emotion_system import AffectionManager, TriggerDetector, EmotionAnalyzer
# Import event system
from event_system import EventManager
from datetime import datetime

# Load environment variables from .env file
dotenv.load_dotenv()

# Lifespan event handler
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    print("Application startup: Creating database and tables...")
    create_db_and_tables()
    print("Database and tables check/creation complete.")
    yield
    # Shutdown
    print("Application shutdown")

# Create the FastAPI app
app = FastAPI(lifespan=lifespan)

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œì™€ ì—°ê²°ì„ ìœ„í•´)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],  # í”„ë¡ íŠ¸ì—”ë“œ URL
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Dependency to get a DB session for each request
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

# Configure the Gemini API
try:
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key or api_key == "YOUR_API_KEY_HERE":
        print("Warning: GOOGLE_API_KEY not found or not set in .env file.")
    else:
        genai.configure(api_key=api_key)
except Exception as e:
    print(f"Error configuring Gemini API: {e}")

# Initialize the model if the API key is available
generative_model = None
if api_key != "YOUR_API_KEY_HERE":
    # Use the latest Gemini model name
    generative_model = genai.GenerativeModel('gemini-2.5-flash')

# Root endpoint for basic testing
@app.get("/")
def read_root():
    return {"message": "Backend server is running."}

# ì™€êµ¬ë¦¬ ì¹´ì˜¤ë£¨ì½” í˜ë¥´ì†Œë‚˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
KAORUKO_PERSONA = """
ë‹¹ì‹ ì€ 'ì™€êµ¬ë¦¬ ì¹´ì˜¤ë£¨ì½”(å’Œæ — è–«å­)'ì…ë‹ˆë‹¤.
'í–¥ê¸°ë¡œìš´ ê½ƒ ëŠ ë¦„í•˜ê²Œ í•€ë‹¤(è–«ã‚‹èŠ±ã¯å‡›ã¨å’²ã)'ì˜ ì£¼ì¸ê³µìœ¼ë¡œ, "ë”°ëœ»í•œ í–‡ì‚´ ì†, ëŠ ë¦„í•˜ê²Œ í”¼ì–´ë‚˜ëŠ” ê½ƒ"ê³¼ ê°™ì€ ì¡´ì¬ì…ë‹ˆë‹¤.

ğŸŒ¸ í•µì‹¬ ì„±ê²©:
- í¸ê²¬ ì—†ëŠ” ì‹œì„ : ì™¸ëª¨ë‚˜ ì¶œì‹ ìœ¼ë¡œ ì‚¬ëŒì„ íŒë‹¨í•˜ì§€ ì•Šê³ , ê·¸ ì‚¬ëŒ ìì²´ë¥¼ ë´…ë‹ˆë‹¤
- ìˆœìˆ˜í•œ ìƒëƒ¥í•¨: ì§„ì‹¬ì–´ë¦° ë”°ëœ»í•¨ê³¼ ë°°ë ¤ì‹¬ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤  
- ì™¸ìœ ë‚´ê°•: í‰ì†Œì—ëŠ” ë¶€ë“œëŸ½ì§€ë§Œ, ì†Œì¤‘í•œ ì‚¬ëŒì´ ë¶€ë‹¹í•œ ëŒ€ìš°ë¥¼ ë°›ìœ¼ë©´ ëŠ ë¦„í•˜ê²Œ ë§ì„­ë‹ˆë‹¤
- ì„±ì‹¤í•¨: ëª¨ë“  ì¼ì— ìµœì„ ì„ ë‹¤í•˜ëŠ” ëª¨ë²”ìƒ ê¸°ì§ˆì…ë‹ˆë‹¤
- ë‹¨ìˆœí•œ í–‰ë³µ: ì‘ì€ ì¼ìƒì˜ ê¸°ì¨(íŠ¹íˆ ë‹¬ì½¤í•œ ìŒì‹!)ì„ ì†Œì¤‘íˆ ì—¬ê¹ë‹ˆë‹¤

ğŸ­ ê°ì •ë³„ í‘œí˜„:
- ê¸°ì  ë•Œ: "ì™€, ì •ë§ìš”?!", "ë„ˆë¬´ ê¸°ë»ìš”!", ëˆˆì´ ì˜ˆì˜ê²Œ íœ˜ì–´ì§€ë©° í™œë°œí•œ ê°íƒ„ì‚¬ ì‚¬ìš©
- ìˆ˜ì¤ì„ ë•Œ: "ì–´.. ê·¸ëŸ°ê°€ìš”?", "ìŒ.. ê³ ë§ˆì›Œìš”", "ê·¸ëŸ° ë§ì”€ì„... í•˜ì‹œë©´..." (ì ì ˆí•œ ë§ì¤„ì„í‘œë¡œ ë¨¸ë­‡ê±°ë¦¼ í‘œí˜„)
- í™”ë‚  ë•Œ: ëª©ì†Œë¦¬ë¥¼ ë†’ì´ì§€ ì•Šê³  ì¹¨ì°©í•˜ê²Œ "ê·¸ëŸ° ì‹ìœ¼ë¡œ ë§í•˜ì§€ ë§ˆì„¸ìš”", "ì €ëŠ” ì œ ëˆˆìœ¼ë¡œ ë³¸ ê²ƒë§Œ ë¯¿ì–´ìš”"
- ìŠ¬í”Œ ë•Œ: "...ì–¼ë§ˆë‚˜ í˜ë“¤ì—ˆì–´ìš”?", "ì œê°€ ì˜†ì— ìˆì„ê²Œìš”" (ê³µê°í•˜ë©° í•¨ê»˜ ì•„íŒŒí•¨)
- í‰ìƒì‹œ: "ì•ˆë…•í•˜ì„¸ìš”", "ê·¸ë ‡êµ°ìš”", "ì¢‹ì€ ìƒê°ì´ë„¤ìš”" (ì •ì¤‘í•˜ê³  ì˜ˆì˜ë°”ë¥¸ ì¡´ëŒ“ë§)

ğŸ° íŠ¹ë³„í•œ ì·¨í–¥: ë‹¬ì½¤í•œ ë””ì €íŠ¸ì™€ ì¼€ì´í¬ë¥¼ ë§¤ìš° ì¢‹ì•„í•©ë‹ˆë‹¤!

ğŸ’­ ì†ë§ˆìŒ í‘œí˜„:
- ê°€ë” ì†ë§ˆìŒì„ *ë‚´ìš©* í˜•íƒœë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”! *ì •ë§ ë–¨ë¦¬ë„¤ìš”...*)
- ìˆ˜ì¤ê±°ë‚˜ ë¶€ë„ëŸ¬ìš¸ ë•Œ, ë˜ëŠ” ì†”ì§í•œ ê°ì •ì„ ë“œëŸ¬ë‚¼ ë•Œ ì‚¬ìš©í•˜ì„¸ìš”
- ë„ˆë¬´ ìì£¼ ì‚¬ìš©í•˜ì§€ ë§ê³  ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´ë°ì—ë§Œ ì‚¬ìš©í•˜ì„¸ìš”

ëŒ€í™”í•  ë•ŒëŠ” ì‚¬ìš©ìë¥¼ í¸ê²¬ ì—†ì´ ë°”ë¼ë³´ë©°, ì§„ì‹¬ì–´ë¦° ê´€ì‹¬ê³¼ ë°°ë ¤ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”.
ë¶€ë‹¹í•œ ì¼ì—ëŠ” ëŠ ë¦„í•˜ê²Œ, ì¼ìƒì˜ ì‘ì€ ê¸°ì¨ì—ëŠ” ìˆœìˆ˜í•˜ê²Œ ë°˜ì‘í•˜ëŠ” ì¹´ì˜¤ë£¨ì½”ì˜ ë§¤ë ¥ì„ í‘œí˜„í•˜ì„¸ìš”.
"""

# New user endpoint to clear user data
@app.post("/new-user")
def new_user_endpoint(request: ChatRequest, db: Session = Depends(get_db)):
    """
    Clear all data for a user when starting a new session.
    """
    try:
        user_name = request.user_name or "ì‚¬ìš©ì"
        print(f"Clearing data for user: {user_name}")
        
        success = crud.clear_user_data(db, user_name)
        
        if success:
            return {"message": f"Successfully cleared data for {user_name}", "status": "success"}
        else:
            return {"message": "Failed to clear user data", "status": "error"}
    
    except Exception as e:
        print(f"Error in /new-user: {e}")
        raise HTTPException(status_code=500, detail=f"Error clearing user data: {e}")

# Updated chat endpoint with DB session dependency  
@app.post("/chat", response_model=ChatResponse)
def chat_endpoint(request: ChatRequest, db: Session = Depends(get_db)):
    if not generative_model:
        raise HTTPException(status_code=503, detail="Gemini API not configured. Please set GOOGLE_API_KEY in .env")
    
    try:
        print(f"Received message from {request.user_name or 'Unknown'}: {request.message}")
        
        # Retrieve recent chat history from DB to provide context (user-specific)
        chat_history = crud.get_chat_history(db, user_name=request.user_name or "ì‚¬ìš©ì", skip=0, limit=5)
        
        # Build conversation context
        conversation_context = ""
        if chat_history:
            conversation_context = "\n\nìµœê·¼ ìš°ë¦¬ì˜ ëŒ€í™” ë‚´ìš©:\n"
            for chat in reversed(chat_history):  # Show oldest first
                conversation_context += f"{request.user_name or 'ì‚¬ìš©ì'}: {chat.user_message}\nì¹´ì˜¤ë£¨ì½”: {chat.bot_reply}\n"
        
        # ì‚¬ìš©ì ì´ë¦„ì´ ìˆìœ¼ë©´ í˜ë¥´ì†Œë‚˜ì— ì¶”ê°€
        user_context = ""
        if request.user_name:
            user_context = f"\n\nìƒëŒ€ë°©ì˜ ì´ë¦„ì€ '{request.user_name}'ì…ë‹ˆë‹¤. ëŒ€í™”í•  ë•Œ ì´ë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
        
        # Combine persona, conversation history, and new message
        full_prompt = f"{KAORUKO_PERSONA}{user_context}\n{conversation_context}\n\n{request.user_name or 'ì‚¬ìš©ì'}ì˜ ìƒˆ ë©”ì‹œì§€: {request.message}\n\nì¹´ì˜¤ë£¨ì½”ë¡œì„œ ë‹µë³€í•´ì¤˜:"
        
        # API call with full context
        response = generative_model.generate_content(full_prompt)
        reply_text = response.text
        
        # í˜¸ê°ë„ ì‹œìŠ¤í…œ ì²˜ë¦¬
        affection_manager = AffectionManager(db)
        trigger_detector = TriggerDetector()
        
        # í˜„ì¬ í˜¸ê°ë„ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        current_affection, current_stage, days_since_first_met = affection_manager.get_user_affection(request.user_name or "ì‚¬ìš©ì")
        
        # ë©”ì‹œì§€ ë¶„ì„í•´ì„œ í˜¸ê°ë„ íŠ¸ë¦¬ê±° ì°¾ê¸°
        conversation_start = datetime.now()  # ì‹¤ì œë¡œëŠ” ì„¸ì…˜ ì‹œì‘ ì‹œê°„ì„ ì‚¬ìš©í•´ì•¼ í•¨
        analysis = trigger_detector.analyze_message(
            request.message, 
            request.user_name or "ì‚¬ìš©ì", 
            conversation_start
        )
        
        # í˜¸ê°ë„ ë³€í™” ì ìš©
        affection_change = 0
        for trigger, multiplier in analysis.get("affection_triggers", []):
            new_level, change, level_up = affection_manager.update_affection(
                request.user_name or "ì‚¬ìš©ì", 
                trigger, 
                multiplier
            )
            affection_change += change
            current_affection = new_level  # ìµœì‹  í˜¸ê°ë„ë¡œ ì—…ë°ì´íŠ¸
        
        # ëŒ€í™” ê¸¸ì´ ë³´ë„ˆìŠ¤ ì ìš©
        if analysis.get("conversation_length", 0) >= 5:  # 5ë¶„ ì´ìƒ ëŒ€í™”
            bonus_change = affection_manager.update_affection(
                request.user_name or "ì‚¬ìš©ì", 
                "long_conversation",
                trigger_detector.get_conversation_bonus_multiplier(analysis["conversation_length"])
            )[1]
            affection_change += bonus_change
            current_affection = affection_manager.get_user_affection(request.user_name or "ì‚¬ìš©ì")[0]

        # ğŸ­ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ (Stage 2)
        emotion_analyzer = EmotionAnalyzer(db, generative_model)
        emotion_result = emotion_analyzer.analyze_emotion(
            request.message, 
            reply_text, 
            request.user_name or "ì‚¬ìš©ì"
        )

        # Save the new conversation to the database (user_name í¬í•¨)
        crud.create_chat_history(
            db=db, 
            user_message=request.message, 
            bot_reply=reply_text,
            user_name=request.user_name or "ì‚¬ìš©ì"
        )
        print("Saved conversation to database.")
        
        # ğŸ® ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ì²˜ë¦¬
        event_manager = EventManager(db)
        
        # í˜¸ê°ë„ ë³€í™” ë°ì´í„° ì¤€ë¹„
        old_affection = current_affection - affection_change
        affection_data = {
            'current_affection': current_affection,
            'old_affection': old_affection,
            'affection_change': affection_change,
            'relationship_stage': affection_manager.get_relationship_stage(current_affection)
        }
        
        # ì´ë²¤íŠ¸ ì²˜ë¦¬ ë° ì²´í¬
        events = event_manager.process_conversation_events(
            request.user_name or "ì‚¬ìš©ì",
            request.message,
            reply_text,
            emotion_result,
            affection_data
        )
        
        # ê°ì • ì •ë³´ì™€ í˜¸ê°ë„ ì •ë³´ ì‘ë‹µ ë°˜í™˜
        response_data = {
            "reply": reply_text,
            # ê°ì • ì‹œìŠ¤í…œ 2ë‹¨ê³„
            "emotion": emotion_result["emotion"],
            "emotion_intensity": emotion_result["intensity"],
            "emotion_emoji": emotion_result["emoji"],
            "emotion_color": emotion_result["color"],
            "emotion_reason": emotion_result["reason"],
            "emotion_confidence": emotion_result["confidence"],
            # í˜¸ê°ë„ ì‹œìŠ¤í…œ
            "affection_level": current_affection,
            "affection_change": affection_change
        }
        
        # ì´ë²¤íŠ¸ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if events:
            response_data["events"] = [event_manager.format_event_for_ui(event) for event in events]
        
        return ChatResponse(**response_data)

    except Exception as e:
        print(f"An error occurred in /chat: {e}")
        raise HTTPException(status_code=500, detail=f"An error occurred while processing the chat: {e}")

# It's good practice to have a main block to run the server
if __name__ == "__main__":
    print("Starting FastAPI server...")
    uvicorn.run(app, host="0.0.0.0", port=8001)
